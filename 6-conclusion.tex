Answering the second research question ``\textbf{How does the accuracy of neural network models changes relative to the number of classes in file fragment classification?}'', 
it was observed that an increase in the number of extensions selected to compose the training tends to decrease accuracy and to decrease variation in results. But the number of classes alone is not as important as the type of extension selected: some file types when included in the experiment have a much higher negative impact than others. This observation was demonstrated in the ``hard file types first'' and ``easy file types first'' of Figure \ref{fig:nclasses}, where the file types selected to compose were intentionally chosen, once to degrade results and once to improve them.


File types that contain images or that use compression were identified as those that have the highest negative effect on results, which suggests that their entropy may contribute to the error.

% \levelB{Limitations, threats to validity and future work}
The number of samples taken was small when compared to the number of all possible file types combinations. This imposes a limit on the conclusions that can be reached, and this limitation is hard to overcome.

The group that emerged as file types that most degrade results are files that use compression or contain images. While they are known for their high entropy, no measure of entropy was used to reinforce this claim.
This aspect is addressed in the next chapter.
